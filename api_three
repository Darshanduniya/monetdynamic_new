from airflow import DAG
from airflow.models import DagRun
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta

def get_last_execution_date(dag_id):
    # Retrieve the last execution of the DAG
    dag_runs = DagRun.find(dag_id=dag_id, state='success')

    if dag_runs:
        # Sort the dag_runs based on execution_date in descending order
        sorted_dag_runs = sorted(dag_runs, key=lambda run: run.execution_date, reverse=True)
        last_execution_date = sorted_dag_runs[0].execution_date

        # Check if the last execution falls within the current week
        current_date = datetime.now().date()
        start_of_week = current_date - timedelta(days=current_date.weekday())
        end_of_week = start_of_week + timedelta(days=6)

        if start_of_week <= last_execution_date.date() <= end_of_week:
            print(f"DAG '{dag_id}' has already been triggered in the current week.")
        else:
            # Trigger the DAG here
            print(f"DAG '{dag_id}' will be triggered now.")

    else:
        # Trigger the DAG here if no previous execution found
        print(f"No successful executions found for DAG '{dag_id}'. DAG will be triggered now.")

# Define the DAG
dag = DAG(
    dag_id='get_last_execution_date_dag',
    start_date=datetime(2023, 7, 12),
    schedule_interval=None
)

# Define the PythonOperator task
get_execution_date_task = PythonOperator(
    task_id='get_execution_date',
    python_callable=get_last_execution_date,
    op_kwargs={'dag_id': 'your_dag_id'},
    dag=dag
)

# Set the task dependencies
get_execution_date_task
