from airflow import DAG, models
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta
import pymonetdb
import subprocess
import logging

default_args = {
    'max_active_runs': 1,
    'retries': 3,
    'retry_delay': timedelta(seconds=30)
}

dag = DAG(
    "UK_HANDSHAKE",
    default_args=default_args,
    schedule_interval='*/10 * * * *',
    start_date=datetime(2023, 5, 14),
    catchup=False,
)

def read_industry_names(filename):
    with open(filename, 'r') as file:
        return [line.strip() for line in file]

def read_industries(filename):
    with open(filename, 'r') as file:
        return [line.strip() for line in file]

def read_monetdb_credentials(filename):
    credentials = {}
    with open(filename, 'r') as file:
        for line in file:
            key, value = line.strip().split('=')
            credentials[key] = value
    return credentials

# File paths
industry_names_file = '/path/to/industry_names.txt'
industries_file = '/path/to/industries.txt'
monetdb_credentials_file = '/path/to/monetdb_credentials.txt'

# Read industry names and industries from files
industry_names = read_industry_names(industry_names_file)
industries = read_industries(industries_file)

# Read MonetDB connection credentials from file
monetdb_credentials = read_monetdb_credentials(monetdb_credentials_file)

# Weekly job and monthly job lists
weekly_jobs = ['tec_pos_ikw', 'tec_pos_osw', 'apl_pos_opm', 'apl_pos_stm']
monthly_jobs = ['tec_pos_cet', 'tec_pos_bea']

def execute_monet_query(industry_name, industry, monetdb_credentials):
    conn = pymonetdb.connect(
        username=monetdb_credentials['username'],
        password=monetdb_credentials['password'],
        hostname=monetdb_credentials['hostname'],
        port=int(monetdb_credentials['port']),
        database=monetdb_credentials['database']
    )
    cursor = conn.cursor()

    query = f'''select count(*) from "execution_log" where operation_type='ab' and job_status='SUCCESS' and sys.str_to_date("execution_end_time",'%y-%m-%d')=current_date AND industry_name='{industry_name}' and flag='0' '''
    cursor.execute(query)

    results = cursor.fetchone()[0]
    results = int(results)

    query_two = f'''select offline_mart from "LATES_REFRESH_DETAILS" WHERE industry='{industry}' '''
    cursor.execute(query_two)

    result_two = cursor.fetchone()[0]
    print(result_two)

    if results > 0:
        if industry_name in weekly_jobs:
            job_type = 'weekly'
            print(f"{industry_name} is a weekly job")
        elif industry_name in monthly_jobs:
            job_type = 'monthly'
            print(f"{industry_name} is a monthly job")
        else:
            job_type = 'unknown'
            print(f"Unknown job type for {industry_name}")

        if results > 0 and result_two == 'B':
            if job_type == 'weekly':
                dag_id = f'{industry_name}_B'
                dagrun = models.DagRun.find(dag_id=dag_id, state='success', order_by=['execution_date'], limit=1)
                if dagrun:
                    prev_execution_date = dagrun[0].execution_date
                    print(f"Previous execution date of {dag_id}: {prev_execution_date}")

                    last_run_date = prev_execution_date  # Store the previous execution date of the DAG
                    print(f"Last run date of {dag_id}: {last_run_date}")

                    if last_run_date >= '{{ macros.ds_start_of_week(execution_date) }}' and last_run_date <= '{{ macros.ds_end_of_week(execution_date) }}':
                        last_executed_date = last_run_date  # Assign the last executed date of the respective DAG
                        print(f"Last executed date of {dag_id}: {last_executed_date}")
                    else:
                        subprocess.run(['airflow', 'dags', 'trigger', dag_id])
                        last_executed_date = None  # DAG was triggered in the current week, no last executed date available

                    update_query = f'''UPDATE "execution_log" SET dag_flag=1 WHERE operation_type='ab' and job_status='SUCCESS' and sys.str_to_date("execution_end_time",'%y-%m-%d')=current_date AND industry_name='{industry_name}' AND dag_flag=0 '''
                    cursor.execute(update_query)
                    conn.commit()

            elif job_type == 'monthly':
                dag_id = f'{industry_name}_B'
                subprocess.run(['airflow', 'dags', 'trigger', dag_id])
                last_executed_date = None  # DAG was triggered, no last executed date available

                update_query = f'''UPDATE "execution_log" SET dag_flag=1 WHERE operation_type='ab' and job_status='SUCCESS' and sys.str_to_date("execution_end_time",'%y-%m-%d')=current_date AND industry_name='{industry_name}' AND dag_flag=0 '''
                cursor.execute(update_query)
                conn.commit()

        elif results > 0 and result_two == 'A':
            if job_type == 'weekly':
                dag_id = f'{industry_name}_B'
                subprocess.run(['airflow', 'dags', 'trigger', dag_id])
                last_executed_date = None  # DAG was triggered, no last executed date available

                update_query = f'''UPDATE "execution_log" SET dag_flag=1 WHERE operation_type='ab' and job_status='SUCCESS' and sys.str_to_date("execution_end_time",'%y-%m-%d')=current_date AND industry_name='{industry_name}' AND dag_flag=0 '''
                cursor.execute(update_query)
                conn.commit()

    return last_executed_date

task = PythonOperator(
    task_id='execute_monet_query',
    python_callable=execute_monet_query,
    op_kwargs={'industry_name': 'UK_HANDSHAKE', 'industry': 'your_industry', 'monetdb_credentials': monetdb_credentials},
    dag=dag
)
